general:
  exp_name: demo
  gpus: 1
  seed: 0
  exp_save_root: 'experiments/'
  weights_save_frequency: 4
  recon_frame_amount_train: 8 # for saving gpu memory, in training only 8 frames are used
  recon_frame_amount_val: 25
  recon_neighbor_frames_train: all # using all neighboring frames for training
  recon_neighbor_frames_val: 4 # using minus plus 4 neighboring frames (in total 9 frames) for validation
  weighting_motion: 0  # weighting factor for final loss motion warping term, in this work, we set it to 0
  weighting_recon: 1 # weighting factor for final loss recon term

training:
  num_epochs: &epochs 60
#  restore_ckpt: experiments/model_public.pth
  restore_ckpt: False
  use_mixed_precision: True

network:
  motion_estimator: GRAFT  # can be any other motion estimator, e.g, VoxelMorph, PWC, RAFT, etc.
  dataConsistency: DCPMMotion
  BP_recon: True # if set to False, then no backprop for recon and degrade to the conventional MoCo method
  DCPMMotion:
    max_iter: 10
    weight_init: !!float 1e12 # if set to 1e12, then no regularization term is used in DCPM (weighting for it is 1/1e12)
    tol: !!float 1e-12
  GRAFT:
    frameblock: True
    feature_dim_replicate: True # feature extractor in graft requires im1 and im2 has same feature dim, either both =1 or =3
    iters: 12
    graft_small: False
  DCPM:
    max_iter: 10
    weight_init: !!float 1e12
    tol: !!float 1e-12
  other_motion_estimator: todo

loss_base: &loss
  photometric:
    mode: charbonnier  # can be charbonnier, L1, L2
  sp_smooth:
    mode: forward # can be forward, central
    grad: 1 # can be 1, 2
    boundary_awareness: False
  temp_smooth: # only in group_mode
    mode: forward
    grad: 1
  psnr:
    magnitude_psnr: True
  LPIPS:
    net_type: alex
    data_convert: True
    detach: True


train_loss_recon:
  <<: *loss
  which: ['photometric']
  loss_weights: [1]
  cardiac_crop_quantitative_metric: False

eval_loss_recon:
  <<: *loss
  which: ['psnr', 'LPIPS']
  loss_weights: [1,1]
  weighting_factor: 1
  cardiac_crop_quantitative_metric: True

train_loss_motion: &flow_loss
  <<: *loss
  which: [ 'photometric', 'sp_smooth', 'temp_smooth' ]
  loss_weights: [ 1, 10, 10 ]
  iterative_losses: [ 'photometric', 'sp_smooth', 'temp_smooth' ]
  iteration_gamma: 0.85
  group_mode: True
  warp_ref_in_loss: True

eval_loss_motion:
  <<: *flow_loss
  which: ['photometric']
  loss_weights: [1]
  iterative_losses: []
  weighting_factor: 1


optimizer:
  which: AdamW
  AdamW:
    lr: 0.0001
    eps: !!float 1e-8
    weight_decay: 0.00001

scheduler:
  which: OneCycleLR
  OneCycleLR:
    max_lr: 0.0001
    pct_start: 0.05
    cycle_momentum: False
    anneal_strategy: linear
    epochs: *epochs
  others: todo





